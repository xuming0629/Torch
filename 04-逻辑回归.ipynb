{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例1 MNIST-手写数字识别系统\n",
    "+ 算法思路\n",
    "    > 准备训练参数\n",
    "\n",
    "    > 准备数据集(训练集和测试集)\n",
    "\n",
    "    > 建立神经网络模型\n",
    "\n",
    "    > 选择优化算法, 计算 loss\n",
    "    \n",
    "    > 训练集上训练模型\n",
    "    \n",
    "    > 测试集上检验正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块导入\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784 # 输入\n",
    "num_classes = 10\n",
    "num_epochs = 50\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset (images and labels)\n",
    "\n",
    "# train_dataset\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                          train=True,\n",
    "                                          transform=transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "\n",
    "# test_dataset\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                         train=False,\n",
    "                                         transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader (input pipeline)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,   # 导出图片数据集\n",
    "                                           batch_size=batch_size,   # 训练选取多少张图片\n",
    "                                           shuffle=True)            # 采取多少个子进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.lr = nn.Linear(784, 10)\n",
    "        self.sm = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lr(x)\n",
    "        x = self.sm(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "if torch.cuda.is_available():\n",
    "    logistic_model.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "# nn.CrossEntropyLoss() computes sfotmax internally\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(logistic_model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/600], Loss: 2.2970\n",
      "Epoch [1/50], Step [200/600], Loss: 2.2959\n",
      "Epoch [1/50], Step [300/600], Loss: 2.2860\n",
      "Epoch [1/50], Step [400/600], Loss: 2.2793\n",
      "Epoch [1/50], Step [500/600], Loss: 2.2732\n",
      "Epoch [1/50], Step [600/600], Loss: 2.2674\n",
      "Epoch [2/50], Step [100/600], Loss: 2.2602\n",
      "Epoch [2/50], Step [200/600], Loss: 2.2520\n",
      "Epoch [2/50], Step [300/600], Loss: 2.2556\n",
      "Epoch [2/50], Step [400/600], Loss: 2.2451\n",
      "Epoch [2/50], Step [500/600], Loss: 2.2314\n",
      "Epoch [2/50], Step [600/600], Loss: 2.2235\n",
      "Epoch [3/50], Step [100/600], Loss: 2.2229\n",
      "Epoch [3/50], Step [200/600], Loss: 2.2128\n",
      "Epoch [3/50], Step [300/600], Loss: 2.2185\n",
      "Epoch [3/50], Step [400/600], Loss: 2.2097\n",
      "Epoch [3/50], Step [500/600], Loss: 2.2022\n",
      "Epoch [3/50], Step [600/600], Loss: 2.1941\n",
      "Epoch [4/50], Step [100/600], Loss: 2.1994\n",
      "Epoch [4/50], Step [200/600], Loss: 2.1823\n",
      "Epoch [4/50], Step [300/600], Loss: 2.1779\n",
      "Epoch [4/50], Step [400/600], Loss: 2.1683\n",
      "Epoch [4/50], Step [500/600], Loss: 2.1702\n",
      "Epoch [4/50], Step [600/600], Loss: 2.1658\n",
      "Epoch [5/50], Step [100/600], Loss: 2.1610\n",
      "Epoch [5/50], Step [200/600], Loss: 2.1659\n",
      "Epoch [5/50], Step [300/600], Loss: 2.1450\n",
      "Epoch [5/50], Step [400/600], Loss: 2.1639\n",
      "Epoch [5/50], Step [500/600], Loss: 2.1451\n",
      "Epoch [5/50], Step [600/600], Loss: 2.1397\n",
      "Epoch [6/50], Step [100/600], Loss: 2.1330\n",
      "Epoch [6/50], Step [200/600], Loss: 2.1182\n",
      "Epoch [6/50], Step [300/600], Loss: 2.1305\n",
      "Epoch [6/50], Step [400/600], Loss: 2.1141\n",
      "Epoch [6/50], Step [500/600], Loss: 2.1234\n",
      "Epoch [6/50], Step [600/600], Loss: 2.1214\n",
      "Epoch [7/50], Step [100/600], Loss: 2.1271\n",
      "Epoch [7/50], Step [200/600], Loss: 2.1196\n",
      "Epoch [7/50], Step [300/600], Loss: 2.1117\n",
      "Epoch [7/50], Step [400/600], Loss: 2.1022\n",
      "Epoch [7/50], Step [500/600], Loss: 2.0966\n",
      "Epoch [7/50], Step [600/600], Loss: 2.0905\n",
      "Epoch [8/50], Step [100/600], Loss: 2.0951\n",
      "Epoch [8/50], Step [200/600], Loss: 2.0970\n",
      "Epoch [8/50], Step [300/600], Loss: 2.0725\n",
      "Epoch [8/50], Step [400/600], Loss: 2.0967\n",
      "Epoch [8/50], Step [500/600], Loss: 2.0759\n",
      "Epoch [8/50], Step [600/600], Loss: 2.0797\n",
      "Epoch [9/50], Step [100/600], Loss: 2.0825\n",
      "Epoch [9/50], Step [200/600], Loss: 2.0567\n",
      "Epoch [9/50], Step [300/600], Loss: 2.0781\n",
      "Epoch [9/50], Step [400/600], Loss: 2.0716\n",
      "Epoch [9/50], Step [500/600], Loss: 2.0652\n",
      "Epoch [9/50], Step [600/600], Loss: 2.0451\n",
      "Epoch [10/50], Step [100/600], Loss: 2.0514\n",
      "Epoch [10/50], Step [200/600], Loss: 2.0536\n",
      "Epoch [10/50], Step [300/600], Loss: 2.0487\n",
      "Epoch [10/50], Step [400/600], Loss: 2.0338\n",
      "Epoch [10/50], Step [500/600], Loss: 2.0565\n",
      "Epoch [10/50], Step [600/600], Loss: 2.0514\n",
      "Epoch [11/50], Step [100/600], Loss: 2.0537\n",
      "Epoch [11/50], Step [200/600], Loss: 2.0361\n",
      "Epoch [11/50], Step [300/600], Loss: 2.0377\n",
      "Epoch [11/50], Step [400/600], Loss: 2.0213\n",
      "Epoch [11/50], Step [500/600], Loss: 2.0097\n",
      "Epoch [11/50], Step [600/600], Loss: 2.0260\n",
      "Epoch [12/50], Step [100/600], Loss: 2.0249\n",
      "Epoch [12/50], Step [200/600], Loss: 2.0273\n",
      "Epoch [12/50], Step [300/600], Loss: 2.0246\n",
      "Epoch [12/50], Step [400/600], Loss: 2.0277\n",
      "Epoch [12/50], Step [500/600], Loss: 2.0031\n",
      "Epoch [12/50], Step [600/600], Loss: 2.0129\n",
      "Epoch [13/50], Step [100/600], Loss: 1.9947\n",
      "Epoch [13/50], Step [200/600], Loss: 2.0005\n",
      "Epoch [13/50], Step [300/600], Loss: 1.9858\n",
      "Epoch [13/50], Step [400/600], Loss: 1.9771\n",
      "Epoch [13/50], Step [500/600], Loss: 1.9976\n",
      "Epoch [13/50], Step [600/600], Loss: 2.0095\n",
      "Epoch [14/50], Step [100/600], Loss: 2.0023\n",
      "Epoch [14/50], Step [200/600], Loss: 1.9969\n",
      "Epoch [14/50], Step [300/600], Loss: 1.9954\n",
      "Epoch [14/50], Step [400/600], Loss: 1.9920\n",
      "Epoch [14/50], Step [500/600], Loss: 1.9660\n",
      "Epoch [14/50], Step [600/600], Loss: 1.9530\n",
      "Epoch [15/50], Step [100/600], Loss: 1.9796\n",
      "Epoch [15/50], Step [200/600], Loss: 1.9786\n",
      "Epoch [15/50], Step [300/600], Loss: 1.9752\n",
      "Epoch [15/50], Step [400/600], Loss: 1.9998\n",
      "Epoch [15/50], Step [500/600], Loss: 1.9551\n",
      "Epoch [15/50], Step [600/600], Loss: 1.9626\n",
      "Epoch [16/50], Step [100/600], Loss: 1.9552\n",
      "Epoch [16/50], Step [200/600], Loss: 1.9448\n",
      "Epoch [16/50], Step [300/600], Loss: 1.9563\n",
      "Epoch [16/50], Step [400/600], Loss: 1.9439\n",
      "Epoch [16/50], Step [500/600], Loss: 1.9499\n",
      "Epoch [16/50], Step [600/600], Loss: 1.9593\n",
      "Epoch [17/50], Step [100/600], Loss: 1.9643\n",
      "Epoch [17/50], Step [200/600], Loss: 1.9527\n",
      "Epoch [17/50], Step [300/600], Loss: 1.9716\n",
      "Epoch [17/50], Step [400/600], Loss: 1.9497\n",
      "Epoch [17/50], Step [500/600], Loss: 1.9713\n",
      "Epoch [17/50], Step [600/600], Loss: 1.9779\n",
      "Epoch [18/50], Step [100/600], Loss: 1.9374\n",
      "Epoch [18/50], Step [200/600], Loss: 1.9458\n",
      "Epoch [18/50], Step [300/600], Loss: 1.9462\n",
      "Epoch [18/50], Step [400/600], Loss: 1.9554\n",
      "Epoch [18/50], Step [500/600], Loss: 1.9765\n",
      "Epoch [18/50], Step [600/600], Loss: 1.9255\n",
      "Epoch [19/50], Step [100/600], Loss: 1.9397\n",
      "Epoch [19/50], Step [200/600], Loss: 1.9412\n",
      "Epoch [19/50], Step [300/600], Loss: 1.9206\n",
      "Epoch [19/50], Step [400/600], Loss: 1.9094\n",
      "Epoch [19/50], Step [500/600], Loss: 1.9400\n",
      "Epoch [19/50], Step [600/600], Loss: 1.9296\n",
      "Epoch [20/50], Step [100/600], Loss: 1.9157\n",
      "Epoch [20/50], Step [200/600], Loss: 1.9069\n",
      "Epoch [20/50], Step [300/600], Loss: 1.9387\n",
      "Epoch [20/50], Step [400/600], Loss: 1.9617\n",
      "Epoch [20/50], Step [500/600], Loss: 1.9343\n",
      "Epoch [20/50], Step [600/600], Loss: 1.9218\n",
      "Epoch [21/50], Step [100/600], Loss: 1.9201\n",
      "Epoch [21/50], Step [200/600], Loss: 1.8879\n",
      "Epoch [21/50], Step [300/600], Loss: 1.9146\n",
      "Epoch [21/50], Step [400/600], Loss: 1.9141\n",
      "Epoch [21/50], Step [500/600], Loss: 1.9301\n",
      "Epoch [21/50], Step [600/600], Loss: 1.9268\n",
      "Epoch [22/50], Step [100/600], Loss: 1.9147\n",
      "Epoch [22/50], Step [200/600], Loss: 1.9269\n",
      "Epoch [22/50], Step [300/600], Loss: 1.8884\n",
      "Epoch [22/50], Step [400/600], Loss: 1.9009\n",
      "Epoch [22/50], Step [500/600], Loss: 1.9238\n",
      "Epoch [22/50], Step [600/600], Loss: 1.9100\n",
      "Epoch [23/50], Step [100/600], Loss: 1.9080\n",
      "Epoch [23/50], Step [200/600], Loss: 1.9069\n",
      "Epoch [23/50], Step [300/600], Loss: 1.8878\n",
      "Epoch [23/50], Step [400/600], Loss: 1.8778\n",
      "Epoch [23/50], Step [500/600], Loss: 1.8837\n",
      "Epoch [23/50], Step [600/600], Loss: 1.9379\n",
      "Epoch [24/50], Step [100/600], Loss: 1.8871\n",
      "Epoch [24/50], Step [200/600], Loss: 1.9024\n",
      "Epoch [24/50], Step [300/600], Loss: 1.9045\n",
      "Epoch [24/50], Step [400/600], Loss: 1.8905\n",
      "Epoch [24/50], Step [500/600], Loss: 1.9161\n",
      "Epoch [24/50], Step [600/600], Loss: 1.8892\n",
      "Epoch [25/50], Step [100/600], Loss: 1.8859\n",
      "Epoch [25/50], Step [200/600], Loss: 1.9079\n",
      "Epoch [25/50], Step [300/600], Loss: 1.8755\n",
      "Epoch [25/50], Step [400/600], Loss: 1.9080\n",
      "Epoch [25/50], Step [500/600], Loss: 1.8965\n",
      "Epoch [25/50], Step [600/600], Loss: 1.8886\n",
      "Epoch [26/50], Step [100/600], Loss: 1.8698\n",
      "Epoch [26/50], Step [200/600], Loss: 1.8987\n",
      "Epoch [26/50], Step [300/600], Loss: 1.8765\n",
      "Epoch [26/50], Step [400/600], Loss: 1.9034\n",
      "Epoch [26/50], Step [500/600], Loss: 1.8956\n",
      "Epoch [26/50], Step [600/600], Loss: 1.8845\n",
      "Epoch [27/50], Step [100/600], Loss: 1.8922\n",
      "Epoch [27/50], Step [200/600], Loss: 1.8948\n",
      "Epoch [27/50], Step [300/600], Loss: 1.8782\n",
      "Epoch [27/50], Step [400/600], Loss: 1.8604\n",
      "Epoch [27/50], Step [500/600], Loss: 1.8917\n",
      "Epoch [27/50], Step [600/600], Loss: 1.8977\n",
      "Epoch [28/50], Step [100/600], Loss: 1.8789\n",
      "Epoch [28/50], Step [200/600], Loss: 1.8766\n",
      "Epoch [28/50], Step [300/600], Loss: 1.8703\n",
      "Epoch [28/50], Step [400/600], Loss: 1.8918\n",
      "Epoch [28/50], Step [500/600], Loss: 1.8762\n",
      "Epoch [28/50], Step [600/600], Loss: 1.8690\n",
      "Epoch [29/50], Step [100/600], Loss: 1.8599\n",
      "Epoch [29/50], Step [200/600], Loss: 1.8661\n",
      "Epoch [29/50], Step [300/600], Loss: 1.8615\n",
      "Epoch [29/50], Step [400/600], Loss: 1.8633\n",
      "Epoch [29/50], Step [500/600], Loss: 1.8511\n",
      "Epoch [29/50], Step [600/600], Loss: 1.8772\n",
      "Epoch [30/50], Step [100/600], Loss: 1.8694\n",
      "Epoch [30/50], Step [200/600], Loss: 1.8619\n",
      "Epoch [30/50], Step [300/600], Loss: 1.8557\n",
      "Epoch [30/50], Step [400/600], Loss: 1.8344\n",
      "Epoch [30/50], Step [500/600], Loss: 1.8525\n",
      "Epoch [30/50], Step [600/600], Loss: 1.8264\n",
      "Epoch [31/50], Step [100/600], Loss: 1.8719\n",
      "Epoch [31/50], Step [200/600], Loss: 1.8347\n",
      "Epoch [31/50], Step [300/600], Loss: 1.8720\n",
      "Epoch [31/50], Step [400/600], Loss: 1.8592\n",
      "Epoch [31/50], Step [500/600], Loss: 1.8527\n",
      "Epoch [31/50], Step [600/600], Loss: 1.8789\n",
      "Epoch [32/50], Step [100/600], Loss: 1.8456\n",
      "Epoch [32/50], Step [200/600], Loss: 1.8562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [300/600], Loss: 1.8507\n",
      "Epoch [32/50], Step [400/600], Loss: 1.8417\n",
      "Epoch [32/50], Step [500/600], Loss: 1.8356\n",
      "Epoch [32/50], Step [600/600], Loss: 1.8727\n",
      "Epoch [33/50], Step [100/600], Loss: 1.8510\n",
      "Epoch [33/50], Step [200/600], Loss: 1.8542\n",
      "Epoch [33/50], Step [300/600], Loss: 1.8519\n",
      "Epoch [33/50], Step [400/600], Loss: 1.8253\n",
      "Epoch [33/50], Step [500/600], Loss: 1.8227\n",
      "Epoch [33/50], Step [600/600], Loss: 1.8354\n",
      "Epoch [34/50], Step [100/600], Loss: 1.7945\n",
      "Epoch [34/50], Step [200/600], Loss: 1.8284\n",
      "Epoch [34/50], Step [300/600], Loss: 1.8273\n",
      "Epoch [34/50], Step [400/600], Loss: 1.8541\n",
      "Epoch [34/50], Step [500/600], Loss: 1.8337\n",
      "Epoch [34/50], Step [600/600], Loss: 1.8700\n",
      "Epoch [35/50], Step [100/600], Loss: 1.8263\n",
      "Epoch [35/50], Step [200/600], Loss: 1.8734\n",
      "Epoch [35/50], Step [300/600], Loss: 1.8539\n",
      "Epoch [35/50], Step [400/600], Loss: 1.8303\n",
      "Epoch [35/50], Step [500/600], Loss: 1.8327\n",
      "Epoch [35/50], Step [600/600], Loss: 1.8828\n",
      "Epoch [36/50], Step [100/600], Loss: 1.8137\n",
      "Epoch [36/50], Step [200/600], Loss: 1.8176\n",
      "Epoch [36/50], Step [300/600], Loss: 1.8514\n",
      "Epoch [36/50], Step [400/600], Loss: 1.8371\n",
      "Epoch [36/50], Step [500/600], Loss: 1.8213\n",
      "Epoch [36/50], Step [600/600], Loss: 1.8223\n",
      "Epoch [37/50], Step [100/600], Loss: 1.8327\n",
      "Epoch [37/50], Step [200/600], Loss: 1.8241\n",
      "Epoch [37/50], Step [300/600], Loss: 1.8338\n",
      "Epoch [37/50], Step [400/600], Loss: 1.8460\n",
      "Epoch [37/50], Step [500/600], Loss: 1.8286\n",
      "Epoch [37/50], Step [600/600], Loss: 1.8304\n",
      "Epoch [38/50], Step [100/600], Loss: 1.8211\n",
      "Epoch [38/50], Step [200/600], Loss: 1.8305\n",
      "Epoch [38/50], Step [300/600], Loss: 1.8356\n",
      "Epoch [38/50], Step [400/600], Loss: 1.8104\n",
      "Epoch [38/50], Step [500/600], Loss: 1.8163\n",
      "Epoch [38/50], Step [600/600], Loss: 1.8074\n",
      "Epoch [39/50], Step [100/600], Loss: 1.8127\n",
      "Epoch [39/50], Step [200/600], Loss: 1.8434\n",
      "Epoch [39/50], Step [300/600], Loss: 1.8498\n",
      "Epoch [39/50], Step [400/600], Loss: 1.8252\n",
      "Epoch [39/50], Step [500/600], Loss: 1.8270\n",
      "Epoch [39/50], Step [600/600], Loss: 1.8023\n",
      "Epoch [40/50], Step [100/600], Loss: 1.8207\n",
      "Epoch [40/50], Step [200/600], Loss: 1.8338\n",
      "Epoch [40/50], Step [300/600], Loss: 1.8145\n",
      "Epoch [40/50], Step [400/600], Loss: 1.8165\n",
      "Epoch [40/50], Step [500/600], Loss: 1.8043\n",
      "Epoch [40/50], Step [600/600], Loss: 1.8051\n",
      "Epoch [41/50], Step [100/600], Loss: 1.8017\n",
      "Epoch [41/50], Step [200/600], Loss: 1.8187\n",
      "Epoch [41/50], Step [300/600], Loss: 1.8257\n",
      "Epoch [41/50], Step [400/600], Loss: 1.8274\n",
      "Epoch [41/50], Step [500/600], Loss: 1.8456\n",
      "Epoch [41/50], Step [600/600], Loss: 1.8219\n",
      "Epoch [42/50], Step [100/600], Loss: 1.8057\n",
      "Epoch [42/50], Step [200/600], Loss: 1.8084\n",
      "Epoch [42/50], Step [300/600], Loss: 1.8080\n",
      "Epoch [42/50], Step [400/600], Loss: 1.8070\n",
      "Epoch [42/50], Step [500/600], Loss: 1.7979\n",
      "Epoch [42/50], Step [600/600], Loss: 1.7888\n",
      "Epoch [43/50], Step [100/600], Loss: 1.7950\n",
      "Epoch [43/50], Step [200/600], Loss: 1.7958\n",
      "Epoch [43/50], Step [300/600], Loss: 1.7943\n",
      "Epoch [43/50], Step [400/600], Loss: 1.8161\n",
      "Epoch [43/50], Step [500/600], Loss: 1.8179\n",
      "Epoch [43/50], Step [600/600], Loss: 1.7948\n",
      "Epoch [44/50], Step [100/600], Loss: 1.8107\n",
      "Epoch [44/50], Step [200/600], Loss: 1.8092\n",
      "Epoch [44/50], Step [300/600], Loss: 1.8389\n",
      "Epoch [44/50], Step [400/600], Loss: 1.8110\n",
      "Epoch [44/50], Step [500/600], Loss: 1.8295\n",
      "Epoch [44/50], Step [600/600], Loss: 1.8130\n",
      "Epoch [45/50], Step [100/600], Loss: 1.8267\n",
      "Epoch [45/50], Step [200/600], Loss: 1.7896\n",
      "Epoch [45/50], Step [300/600], Loss: 1.7838\n",
      "Epoch [45/50], Step [400/600], Loss: 1.8105\n",
      "Epoch [45/50], Step [500/600], Loss: 1.8010\n",
      "Epoch [45/50], Step [600/600], Loss: 1.8045\n",
      "Epoch [46/50], Step [100/600], Loss: 1.8390\n",
      "Epoch [46/50], Step [200/600], Loss: 1.8153\n",
      "Epoch [46/50], Step [300/600], Loss: 1.7934\n",
      "Epoch [46/50], Step [400/600], Loss: 1.8201\n",
      "Epoch [46/50], Step [500/600], Loss: 1.7809\n",
      "Epoch [46/50], Step [600/600], Loss: 1.8108\n",
      "Epoch [47/50], Step [100/600], Loss: 1.8056\n",
      "Epoch [47/50], Step [200/600], Loss: 1.8049\n",
      "Epoch [47/50], Step [300/600], Loss: 1.7955\n",
      "Epoch [47/50], Step [400/600], Loss: 1.8058\n",
      "Epoch [47/50], Step [500/600], Loss: 1.8042\n",
      "Epoch [47/50], Step [600/600], Loss: 1.7798\n",
      "Epoch [48/50], Step [100/600], Loss: 1.8125\n",
      "Epoch [48/50], Step [200/600], Loss: 1.8193\n",
      "Epoch [48/50], Step [300/600], Loss: 1.7990\n",
      "Epoch [48/50], Step [400/600], Loss: 1.7747\n",
      "Epoch [48/50], Step [500/600], Loss: 1.7674\n",
      "Epoch [48/50], Step [600/600], Loss: 1.7727\n",
      "Epoch [49/50], Step [100/600], Loss: 1.8016\n",
      "Epoch [49/50], Step [200/600], Loss: 1.7739\n",
      "Epoch [49/50], Step [300/600], Loss: 1.8269\n",
      "Epoch [49/50], Step [400/600], Loss: 1.8078\n",
      "Epoch [49/50], Step [500/600], Loss: 1.8356\n",
      "Epoch [49/50], Step [600/600], Loss: 1.8021\n",
      "Epoch [50/50], Step [100/600], Loss: 1.7918\n",
      "Epoch [50/50], Step [200/600], Loss: 1.7824\n",
      "Epoch [50/50], Step [300/600], Loss: 1.7793\n",
      "Epoch [50/50], Step [400/600], Loss: 1.7880\n",
      "Epoch [50/50], Step [500/600], Loss: 1.8057\n",
      "Epoch [50/50], Step [600/600], Loss: 1.8145\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape images to (batch_size, input_size)\n",
    "        images = images.reshape(-1,28*28)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = logistic_model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 84 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = logistic_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(logistic_model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
